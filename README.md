# A Deep Learning Architecture

-----



>#### This is a basic implementation of an `artificial neural network` from A to Z. The aim of course is not of course to mimic the famous <a href="https://keras.io/">Keras</a> `Fran√ßois chollet`'s library, the work is far from that ... 

-----

**The aim is to provide a simple and clear implementation of a basic `ANN`, showing the differant bricks of the structure, and the basics of each part.**

**This work is based on <a href="http://neuralnetworksanddeeplearning.com/">Deep Learning Book</a> the outstanding introduction to neural networks by `Michael Nielsen`.**

**Step after, we move to build an RMB structure `Restricted Boltzmann Machine`, and provide some efficient algorithms for training such as `Contrastive Divergence` <a href="http://www.robots.ox.ac.uk/~ojw/files/NotesOnCD.pdf">(See here !)</a> using MCMC `Markov Chain Monte Carlo` (as particular case of Metropolis Hasting algorithms) techniques. This part will be based on the outsdanding paper<a href="http://cms.dm.uba.ar/academico/materias/1ercuat2018/probabilidades_y_estadistica_C/5a89b5075af5cbef5becaf419457cdd77cc9.pdf">An introducion to restricted boltzmann machines</a>. The paper provides more algorithms for the training, and a deep mathematical understanding behind RBM as a probabilistic graphical model.**

>**The project's comming steps :**

<img src="https://github.com/Mohammed-Hssein/Deep-Learning-architecture/blob/master/ressources/DNAProject.png">



